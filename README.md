# LLM Fine-Tuning Feedback Collection

## Overview

This repository contains a collection of feedback for fine-tuned versions of various large language models (LLMs) on two Kaggle datasets:

1. Kaggle Essay Dataset
2. Kaggle Short Answer Dataset

The models included in this feedback collection are:

- Meta's Llama 3-8B-Instruct
- Google's Gemma 1.1-7B-Instruct
- Microsoft's Phi-3-3.8B-Instruct
- Mistral AI's Mistral-v0.2-Instral

## Purpose

The goal of this project is to provide a comprehensive resource for researchers, developers, and AI enthusiasts to understand the performance, strengths, and weaknesses of different LLMs when fine-tuned on specific datasets. This feedback can be valuable for:

- Comparing model performances
- Identifying areas for improvement
- Guiding future fine-tuning efforts
- Understanding dataset-specific challenges

## Repository Structure

.
├── aes/
├── asas/
└── README.md

## Acknowledgments

- Kaggle for providing the datasets
- The teams behind Llama 3, Gemma, Phi-3, and Mistral for their open-source contributions to the AI community

## Contact

For any questions or concerns, please open an issue in this repository or contact the maintainers at [christopher.ormerod@gmail.com](mailto:christopher.ormerod@gmail.com).